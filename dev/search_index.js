var documenterSearchIndex = {"docs":
[{"location":"getting-started/#BoostingDeciionTrees.jl","page":"Getting started","title":"BoostingDeciionTrees.jl","text":"(Image: Stable) (Image: Dev) (Image: Build Status) (Image: Coverage)","category":"section"},{"location":"getting-started/#Running-the-package-locally","page":"Getting started","title":"Running the package locally","text":"To use this package locally, open a Julia REPL inside the project structure and run:\n\njulia> ]activate .\n\njulia> include(\"src/BoostingDecisionTrees.jl\")\n\njulia> using .BoostingDecisionTrees","category":"section"},{"location":"getting-started/#Examples","page":"Getting started","title":"Examples","text":"","category":"section"},{"location":"getting-started/#Gini-Impurity","page":"Getting started","title":"Gini Impurity","text":"First define your dataset that you want to train on. Please keep in mind that the current implementation only allows a matrix for X\n\njulia>  X = [1 2; 2 3; 11 21; 12 22]\n\njulia> y = [0, 0, 1, 1]\n\njulia> stump = train_stump(X, y)\n\nNow you can use the created stump to predict the labels for an input matrix, e.g.:\n\njulia>  predict_stump(stump, X)","category":"section"},{"location":"#BoostingDecisionTrees","page":"Documentation","title":"BoostingDecisionTrees","text":"Documentation for BoostingDecisionTrees.\n\n","category":"section"},{"location":"#BoostingDecisionTrees.best_split-Tuple{Any, Any}","page":"Documentation","title":"BoostingDecisionTrees.best_split","text":"best_split(feature, labels)\n\nParameters:\n\n'feature': a vector of numerical values\n'labels': a vector of class labels (same length as 'feature')\n\nReturn:\n\n'best_threshold': best numerical value to split the 'feature' on\n'best_gini': weighted gini impurity after the split\n\n\n\n\n\n","category":"method"},{"location":"#BoostingDecisionTrees.best_split_information_gain-Tuple{Matrix, Vector}","page":"Documentation","title":"BoostingDecisionTrees.best_split_information_gain","text":"Finds the feature index that gives the highest information gain. \n\n\n\n\n\n","category":"method"},{"location":"#BoostingDecisionTrees.entropy-Tuple{Vector}","page":"Documentation","title":"BoostingDecisionTrees.entropy","text":"This is needed to later calculate IG \n\n\n\n\n\n","category":"method"},{"location":"#BoostingDecisionTrees.gini_impurity-Tuple{Any}","page":"Documentation","title":"BoostingDecisionTrees.gini_impurity","text":"gini_impurity(classes)\n\nCompute the Gini impurity of a vector of class labels 'classes'.\n\n\n\n\n\n","category":"method"},{"location":"#BoostingDecisionTrees.information_gain-Tuple{Vector, Vector}","page":"Documentation","title":"BoostingDecisionTrees.information_gain","text":"Computes the information gain obtained by splitting on one feature column. \nThis calculates how helpful a selector is by comparing entropy of a feature before and after applying it\n\n\n\n\n\n","category":"method"}]
}
